#!/bin/bash
# Copyright 2023 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#      http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

set -o pipefail
set -o errexit

# shellcheck disable=SC1090
source ./builders/tools/builder.sh

WORKSPACE="$(git rev-parse --show-toplevel)"

# Script input params
EXTRA_SERVER_WAIT_TIMEOUT="5m"
MINIMUM_SERVER_WAIT_SECS=60
NUMBER_OF_LOOKUP_KEYS_LIST="1 10 50 100"
GHZ_TAGS="{}"

# Additional GHZ tags per deployment/udf
DEPLOYMENT_GHZ_TAGS="{}"
UDF_GHZ_TAGS="{}"

# Input to run_benchmark script
declare RUN_BENCHMARK_ARGS

# Deployment vars
declare SERVER_ADDRESS
declare SERVER_ENDPOINT

# CSV I/O
declare -a BENCHMARK_CSVS
CSV_OUTPUT="${WORKSPACE}/dist/tools/latency_benchmarking/output/output.csv"
DOCKER_OUTPUT_CSV="/tmp/latency_benchmarking/output/deploy_and_benchmark/output.csv"
readonly DOCKER_OUTPUT_CSV

# run_benchmarks writes output to this directory
CSV_SUMMARY_INPUT_DIR="${WORKSPACE}/dist/tools/latency_benchmarking/output"
DOCKER_INPUT_DIR="/tmp/latency_benchmarking/output"
readonly DOCKER_INPUT_DIR

DESTROY_INSTANCES=0

trap _destroy EXIT
function _destroy() {
  if [[ ${DESTROY_INSTANCES} == 1 ]]; then
    printf "Running terraform destroy\n"
    builders/tools/terraform -chdir="${WORKSPACE}"/production/terraform/aws/environments \
      destroy --var-file="${TF_VAR_FILE}" --auto-approve >/dev/null
  fi
}

trap _trap ERR
function _trap() {
  local -r -i STATUS=$?
  FAILED_COMMAND="${BASH_COMMAND}"
  printf "Failed command: %s\n" "${FAILED_COMMAND}"
  exit ${STATUS}
}

function usage() {
  local -r -i exitval=${1-1}
  cat &>/dev/stderr <<USAGE
usage:
  ${BASH_SOURCE[0]}
  TODO: Add usage description
USAGE
  # shellcheck disable=SC2086
  exit ${exitval}
}

function set_benchmark_args() {
  SERVER_ADDRESS="lusa.kv-server.privacysandboxdemo.app:8443"
  local -a RUN_BENCHMARK_GHZ_TAGS
  RUN_BENCHMARK_GHZ_TAGS=$(jq -s -c 'add' <(echo "${GHZ_TAGS}") \
    <(echo "${DEPLOYMENT_GHZ_TAGS}") \
    <(echo "${UDF_GHZ_TAGS}"))
  RUN_BENCHMARK_ARGS=(
      --number-of-lookup-keys-list "${NUMBER_OF_LOOKUP_KEYS_LIST[@]}"
      --server-address "${SERVER_ADDRESS}"
      --ghz-tags "${RUN_BENCHMARK_GHZ_TAGS}"
      --snapshot-dir "${SNAPSHOT_DIR}"
      )
  }

function run_benchmarks() {
  set_benchmark_args
  printf "BENCHMARK ARGS: %s\n" "${RUN_BENCHMARK_ARGS[*]}"

  local BENCHMARK_OUTPUT
  BENCHMARK_OUTPUT=$(./tools/latency_benchmarking/run_benchmarks "${RUN_BENCHMARK_ARGS[@]}")
  BENCHMARK_CSVS+=(
    "$(echo "${BENCHMARK_OUTPUT}" | tail -n 1 2>&1 | tee /dev/tty)"
  )
}

function set_server_address() {
  # Build HTTP server endpoint from tf output
  local SERVER_URL
  local SERVER_HOSTNAME
  SERVER_URL=$([[ "$1" =~ \"(.*)\" ]] && echo "${BASH_REMATCH[1]}")
  SERVER_ENDPOINT="${SERVER_URL}/v1/getvalues?keys=hi"
  # Build gRPC server address from tf output
  SERVER_HOSTNAME=$([[ "${SERVER_URL}" =~ https://(.*) ]] && echo "${BASH_REMATCH[1]}")
  SERVER_ADDRESS="${SERVER_HOSTNAME}:8443"
}

# TODO: GCP
function deploy_and_benchmark() {
  printf "Running terraform init\n"
  builders/tools/terraform \
    -chdir=production/terraform/aws/environments \
    init --backend-config="${TF_BACKEND_CONFIG}" \
    --var-file="${TF_VAR_FILE}" --reconfigure -input=false  \
    >/dev/null

  printf "Running terraform apply with var file: %s\n" "${TF_VAR_FILE}"
  printf "and var overrides: %s\n" "${VAR_OVERRIDES[*]}"
  local TF_APPLY_LAST_LINE
  TF_APPLY_LAST_LINE=$(builders/tools/terraform \
    -chdir=production/terraform/aws/environments \
    apply --var-file="${TF_VAR_FILE}" "${VAR_OVERRIDES[@]}" \
    -auto-approve | tail -n 1)
  printf "Done applying terraform, waiting for server to be ready\n"

  set_server_address "${TF_APPLY_LAST_LINE}"

  # Wait for potential instance teardown before periodically checking if server is ready
  sleep "${MINIMUM_SERVER_WAIT_SECS}"

  # Wait for server to be up
  timeout --foreground "${EXTRA_SERVER_WAIT_TIMEOUT}" bash -c \
    "until curl --output /dev/null --silent --fail ${SERVER_ENDPOINT};do sleep 15; done"
  printf "Server ready, running benchmarks\n"

  # Iterate through each given UDF
  # Upload delta file, run benchmarks, then remove it
  if [[ -d "${UDF_DELTA_DIR}" ]]; then
    for FILE in "${UDF_DELTA_DIR}"/*; do
      local FILENAME
      FILENAME=$(basename "${FILE}")
      aws s3 cp "${FILE}" "${DATA_BUCKET}/${FILENAME}"
      # Allow some time for server to pick up new UDF
      sleep 60
      UDF_GHZ_TAGS="{ \"udf_delta_file\": \"${FILENAME}\" }"
      run_benchmarks
      aws s3 rm "${DATA_BUCKET}/${FILENAME}"
    done
  else
    run_benchmarks
  fi
}

while [[ $# -gt 0 ]]; do
  case "$1" in
    --tf-var-file)
      TF_VAR_FILE="$2"
      shift 2 || usage
      ;;
    --tf-backend-config)
      TF_BACKEND_CONFIG="$2"
      shift 2 || usage
      ;;
    --tf-overrides)
      TF_OVERRIDES="$2"
      shift 2
      ;;
    --csv-output)
      CSV_OUTPUT="$2"
      shift 2
      ;;
    --snapshot-dir)
      SNAPSHOT_DIR="$2"
      shift 2
      ;;
    --udf-delta-dir)
      UDF_DELTA_DIR="$2"
      shift 2
      ;;
    --data-bucket)
      DATA_BUCKET="$2"
      shift 2
      ;;
    --extra-server-wait-timeout)
      EXTRA_SERVER_WAIT_TIMEOUT="$2"
      shift 2
      ;;
    --number-of-lookup-keys-list)
      NUMBER_OF_LOOKUP_KEYS_LIST="$2"
      shift 2
      ;;
    --ghz-tags)
      GHZ_TAGS="$2"
      shift 2
      ;;
    --cleanup-deployment)
      DESTROY_INSTANCES=1
      shift
      ;;
    --minimum-server-wait-secs)
      MINIMUM_SERVER_WAIT_SECS=1
      shift
      ;;
    -h | --help) usage 0 ;;
    *) usage ;;
  esac
done

# Check for SNAPSHOT_DIR. If not available, exit.
if [[ -z "${SNAPSHOT_DIR}" || ! -d "${SNAPSHOT_DIR}" ]]; then
  printf "snapshot-dir not found:%s\n" "${SNAPSHOT_DIR}"
  exit 1;
fi

# No terraform variable overrides, deploy and benchmark without overrides
if [[ -z "${TF_OVERRIDES}" ]]; then
  deploy_and_benchmark "${GHZ_TAGS}"
else
  # Terraform override file found:
  # Each row defines a set of overrides for terraform variables.
  # Pass the overrides to deploy_and_benchmark function and set
  # them as tags in the ghz call.
  while IFS=',' read -ra VARS; do
    declare -a VAR_OVERRIDES=()
    DEPLOYMENT_GHZ_TAGS="{}"
    for VAR in "${VARS[@]}"; do
        VAR_OVERRIDES+=(-var "${VAR}")
        OVERRIDE_VAR_GHZ_TAG=$(echo "${VAR}" | jq -s -R 'split("\n") | .[0] | split("=") | {(.[0]): .[1]}')
        DEPLOYMENT_GHZ_TAGS=$(jq -s -c 'add' <(echo "${DEPLOYMENT_GHZ_TAGS}") <(echo "${OVERRIDE_VAR_GHZ_TAG}"))
    done
    deploy_and_benchmark
  done < "${TF_OVERRIDES}"
fi

# Benchmarks done, merge CSVs

# Map csv summary files from run_benchmarks to docker volume paths
# so that we can access them from within builders/tools/bazel-debian
declare -a DOCKER_BENCHMARK_CSVS
for BENCHMARK_CSV in "${BENCHMARK_CSVS[@]}"; do
  DOCKER_BENCHMARK_CSVS+=(
    "${DOCKER_INPUT_DIR}${BENCHMARK_CSV#"${CSV_SUMMARY_INPUT_DIR}"}"
  )
done
touch "${CSV_OUTPUT}"
# Run merge_csvs python script
EXTRA_DOCKER_RUN_ARGS+=" --volume ${CSV_SUMMARY_INPUT_DIR}:${DOCKER_INPUT_DIR} --volume ${CSV_OUTPUT}:${DOCKER_OUTPUT_CSV} " \
  builders/tools/bazel-debian run //tools/latency_benchmarking:merge_csvs \
  -- \
  --csv-inputs "${DOCKER_BENCHMARK_CSVS[@]}" \
  --csv-output "${DOCKER_OUTPUT_CSV}"

printf "Results in: %s\n" "${CSV_OUTPUT}"
